{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12234285,"sourceType":"datasetVersion","datasetId":7708466},{"sourceId":12242762,"sourceType":"datasetVersion","datasetId":7713909},{"sourceId":12252261,"sourceType":"datasetVersion","datasetId":7719978},{"sourceId":12252678,"sourceType":"datasetVersion","datasetId":7720261}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Implementing Transformer form scratch in pytorch","metadata":{}},{"cell_type":"code","source":"import requests\nimport gzip\nimport shutil\nfrom time import sleep\nimport math\nimport pickle\nfrom collections import Counter,defaultdict","metadata":{"execution":{"iopub.status.busy":"2025-06-24T03:27:19.975883Z","iopub.execute_input":"2025-06-24T03:27:19.976099Z","iopub.status.idle":"2025-06-24T03:27:20.096135Z","shell.execute_reply.started":"2025-06-24T03:27:19.976078Z","shell.execute_reply":"2025-06-24T03:27:20.095447Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from dataclasses import dataclass\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset,DataLoader","metadata":{"execution":{"iopub.status.busy":"2025-06-24T03:27:20.097465Z","iopub.execute_input":"2025-06-24T03:27:20.097699Z","iopub.status.idle":"2025-06-24T03:27:24.181214Z","shell.execute_reply.started":"2025-06-24T03:27:20.097675Z","shell.execute_reply":"2025-06-24T03:27:24.180540Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"base_url = \"https://github.com/multi30k/dataset/raw/refs/heads/master/data/task1/raw/\"\n\ntrain_url = (\"train.de.gz\",\"train.en.gz\")\nval_url = (\"val.de.gz\",\"val.en.gz\",)\ntest_url = (\"test_2016_flickr.de.gz\",\"test_2016_flickr.en.gz\",)","metadata":{"execution":{"iopub.status.busy":"2025-06-24T03:29:48.355947Z","iopub.execute_input":"2025-06-24T03:29:48.356706Z","iopub.status.idle":"2025-06-24T03:29:48.360538Z","shell.execute_reply.started":"2025-06-24T03:29:48.356680Z","shell.execute_reply":"2025-06-24T03:29:48.359726Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"@dataclass\nclass ModelArgs:\n    max_lr = 1e-4\n    batch_size = 32\n    embedding_dim = 64\n    no_of_neurons_ffnn = 4*embedding_dim\n    \n    seq_len = 50\n    \n    num_heads = 3\n    \n    en_vocab_size = None\n    de_vocab_size = None\n    \n    \n    attn_dropout = 0.1\n    dropout = 0.1\n    \n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    ","metadata":{"execution":{"iopub.status.busy":"2025-06-24T03:29:50.631260Z","iopub.execute_input":"2025-06-24T03:29:50.631632Z","iopub.status.idle":"2025-06-24T03:29:50.696426Z","shell.execute_reply.started":"2025-06-24T03:29:50.631599Z","shell.execute_reply":"2025-06-24T03:29:50.695827Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"2048/512","metadata":{"execution":{"iopub.status.busy":"2025-06-23T04:53:56.537646Z","iopub.execute_input":"2025-06-23T04:53:56.537893Z","iopub.status.idle":"2025-06-23T04:53:56.555941Z","shell.execute_reply.started":"2025-06-23T04:53:56.537875Z","shell.execute_reply":"2025-06-23T04:53:56.555107Z"},"trusted":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"4.0"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"def download_file(url, file_name, retries=3):\n    for attempt in range(retries):\n        try:\n            with requests.get(url, stream=True, timeout=10) as r:\n                r.raise_for_status()\n                with open(file_name, \"wb\") as f:\n                    for chunk in r.iter_content(chunk_size=8192):\n                        f.write(chunk)\n            print(f\"Downloaded: {file_name}\")\n            break\n        except (requests.exceptions.RequestException, ConnectionResetError) as e:\n            print(f\"Attempt {attempt + 1} failed: {e}\")\n            sleep(2)  # wait before retrying\n            if attempt == retries - 1:\n                print(f\"Failed to download {file_name} after {retries} attempts.\")\n    return file_name\n\ndef extract_data(in_file,out_file):\n    with gzip.open(in_file,\"rb\") as f_in:\n        with open(out_file,\"wb\") as f_out:\n            shutil.copyfileobj(f_in,f_out)\n    \n    print(f\"Extracted : {in_file}\")\n    \n    return out_file\n\ntrain_paths = [ download_file(base_url+url,url) for url in train_url ]\nval_paths = [download_file(base_url+url,url) for url in val_url]\ntest_paths = [download_file(base_url+url,url) for url in test_url]\n\ntrain_paths = [extract_data(file,file[:-3]) for file in train_paths]\nval_paths = [extract_data(file,file[:-3]) for file in val_paths]\ntest_paths = [extract_data(file,file[:-3]) for file in test_paths]\n","metadata":{"execution":{"iopub.status.busy":"2025-06-23T04:53:56.556587Z","iopub.execute_input":"2025-06-23T04:53:56.556787Z","iopub.status.idle":"2025-06-23T04:53:58.419254Z","shell.execute_reply.started":"2025-06-23T04:53:56.556770Z","shell.execute_reply":"2025-06-23T04:53:58.418630Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Downloaded: train.de.gz\nDownloaded: train.en.gz\nDownloaded: val.de.gz\nDownloaded: val.en.gz\nDownloaded: test_2016_flickr.de.gz\nDownloaded: test_2016_flickr.en.gz\nExtracted : train.de.gz\nExtracted : train.en.gz\nExtracted : val.de.gz\nExtracted : val.en.gz\nExtracted : test_2016_flickr.de.gz\nExtracted : test_2016_flickr.en.gz\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!python -m spacy download en_core_web_sm\n!python -m spacy download de_core_news_sm","metadata":{"execution":{"iopub.status.busy":"2025-06-23T04:53:58.420069Z","iopub.execute_input":"2025-06-23T04:53:58.420748Z","iopub.status.idle":"2025-06-23T04:54:16.126913Z","shell.execute_reply.started":"2025-06-23T04:53:58.420723Z","shell.execute_reply":"2025-06-23T04:54:16.126157Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting en-core-web-sm==3.8.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\nCollecting de-core-news-sm==3.8.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.8.0/de_core_news_sm-3.8.0-py3-none-any.whl (14.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hInstalling collected packages: de-core-news-sm\nSuccessfully installed de-core-news-sm-3.8.0\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('de_core_news_sm')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from collections import Counter , defaultdict\nimport io\nimport spacy\n\nen_tokenizer = spacy.load(\"en_core_web_sm\")\nde_tokenizer = spacy.load(\"de_core_news_sm\")\n\ndef tokenize(text,tokenizer):\n    tokens = tokenizer(text)\n    return [token.text.lower for token in tokens]\n\ndef build_vocab(file_path,tokenizer,min_freq=1,speacial_tokens = [\"<bos>\",\"<pad>\",\"<unk>\",\"<eos>\"]):\n    counter = Counter()\n    with open(file_path,\"r\") as f:\n        for string_ in f:\n            tokens = tokenize(string_,tokenizer)\n            counter.update(tokens)\n    tokens = [token for token,freq in counter.items() if freq>=min_freq]\n    vocab = {token:idx for idx,token in enumerate(tokens+speacial_tokens)}\n    unk_idx = vocab[\"<unk>\"]\n    vocab = defaultdict(lambda : unk_idx,vocab)\n    \n    return vocab\n\nde_vocab = build_vocab(train_paths[0],de_tokenizer)\nen_vocab = build_vocab(train_paths[1],en_tokenizer)\n\nModelArgs.de_vocab_size = len(de_vocab)+1\nModelArgs.en_vocab_size = len(en_vocab)+1\n\n","metadata":{"execution":{"iopub.status.busy":"2025-06-23T04:54:16.128042Z","iopub.execute_input":"2025-06-23T04:54:16.128325Z","iopub.status.idle":"2025-06-23T04:59:38.197045Z","shell.execute_reply.started":"2025-06-23T04:54:16.128292Z","shell.execute_reply":"2025-06-23T04:59:38.196435Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def data_process(file_names):\n    data = []\n    \n    raw_de_iter = iter(io.open(file_names[0],encoding=\"utf-8\"))\n    raw_en_iter = iter(io.open(file_names[1],encoding=\"utf-8\"))\n    \n    for raw_de,raw_en in zip(raw_de_iter,raw_en_iter):\n        de_tensor = torch.tensor([de_vocab[token] for token in tokenize(raw_de,de_tokenizer)],dtype=torch.long)\n        en_tensor = torch.tensor([en_vocab[token] for token in tokenize(raw_en,en_tokenizer)],dtype=torch.long)\n        \n        en_tensor = torch.cat([torch.tensor([en_vocab[\"<bos>\"]]), en_tensor , torch.tensor([en_vocab[\"<eos>\"]])])\n        de_tensor = torch.cat([torch.tensor([de_vocab[\"<bos>\"]]), de_tensor , torch.tensor([de_vocab[\"<eos>\"]])])\n        \n        data.append((de_tensor,en_tensor))\n        \n    return data\n\ntrain_data = data_process(train_paths)\nval_data = data_process(val_paths)\ntest_data = data_process(test_paths)","metadata":{"execution":{"iopub.status.busy":"2025-06-23T04:59:38.197852Z","iopub.execute_input":"2025-06-23T04:59:38.198336Z","iopub.status.idle":"2025-06-23T05:05:24.198425Z","shell.execute_reply.started":"2025-06-23T04:59:38.198316Z","shell.execute_reply":"2025-06-23T05:05:24.197866Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# get the data from the local\ntrain_data = torch.load(\"/kaggle/input/transformer-dataset/train_data.pt\")\nval_data = torch.load(\"/kaggle/input/transformer-dataset/val_data.pt\")\ntest_data = torch.load(\"/kaggle/input/transformer-dataset/test_data.pt\")\nwith open(\"/kaggle/input/model-args-transformer/model_args.pkl\",\"rb\") as f:\n    args = pickle.load(f)\nModelArgs.en_vocab_size = args[\"en_vocab_size\"]\nModelArgs.de_vocab_size = args[\"de_vocab_size\"]\n\nwith open(\"/kaggle/input/transformer-dataset/de_voab.pkl\",\"rb\") as f:\n    de_vocab = pickle.load(f)\nwith open(\"/kaggle/input/transformer-dataset/en_vocab.pkl\",\"rb\") as f:\n    en_vocab = pickle.load(f)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T03:29:55.217272Z","iopub.execute_input":"2025-06-24T03:29:55.218088Z","iopub.status.idle":"2025-06-24T03:30:02.767118Z","shell.execute_reply.started":"2025-06-24T03:29:55.218065Z","shell.execute_reply":"2025-06-24T03:30:02.766312Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"\nde_vocab = defaultdict(lambda : de_vocab[\"<unk>\"],de_vocab)\nen_vocab = defaultdict(lambda : en_vocab[\"<unk>\"],en_vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T03:30:02.768192Z","iopub.execute_input":"2025-06-24T03:30:02.768424Z","iopub.status.idle":"2025-06-24T03:30:02.808762Z","shell.execute_reply.started":"2025-06-24T03:30:02.768407Z","shell.execute_reply":"2025-06-24T03:30:02.807972Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"DE_MAX_SEQ_LEN,EN_MAX_SEQ_LEN = 0,0\nfor de,en in train_data:\n    DE_MAX_SEQ_LEN = max(DE_MAX_SEQ_LEN,len(de))\n    EN_MAX_SEQ_LEN = max(EN_MAX_SEQ_LEN,len(en))\n\nDE_MAX_SEQ_LEN,EN_MAX_SEQ_LEN","metadata":{"execution":{"iopub.status.busy":"2025-06-24T03:30:15.031068Z","iopub.execute_input":"2025-06-24T03:30:15.031649Z","iopub.status.idle":"2025-06-24T03:30:15.102344Z","shell.execute_reply.started":"2025-06-24T03:30:15.031625Z","shell.execute_reply":"2025-06-24T03:30:15.101827Z"},"trusted":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(47, 44)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"class TranslationDataset(Dataset):\n    def __init__(self,data):\n        self.data = data\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self,idx):\n        return self.data[idx]\n    \ntrain_dataset = TranslationDataset(train_data)\nval_dataset = TranslationDataset(val_data)\ntest_dataset = TranslationDataset(test_data)","metadata":{"execution":{"iopub.status.busy":"2025-06-24T03:30:15.303876Z","iopub.execute_input":"2025-06-24T03:30:15.304070Z","iopub.status.idle":"2025-06-24T03:30:15.308321Z","shell.execute_reply.started":"2025-06-24T03:30:15.304055Z","shell.execute_reply":"2025-06-24T03:30:15.307790Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"ModelArgs.seq_len","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T03:30:15.659994Z","iopub.execute_input":"2025-06-24T03:30:15.660549Z","iopub.status.idle":"2025-06-24T03:30:15.664796Z","shell.execute_reply.started":"2025-06-24T03:30:15.660530Z","shell.execute_reply":"2025-06-24T03:30:15.664225Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"50"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"def collate_fn(batch,seq_len=ModelArgs.seq_len):\n    \n    def pad_or_truncate(sequence,pad_value):\n        if len(sequence) >= seq_len:\n            mask = torch.full([seq_len],fill_value=1)\n            return sequence[:seq_len],mask\n        elif len(sequence) < seq_len:\n            padding_len = seq_len - len(sequence)\n            mask = torch.cat([torch.full([len(sequence)],fill_value=1) , torch.full([padding_len],fill_value=0)])\n            return torch.cat([sequence,torch.full([padding_len],fill_value=pad_value)]) , mask\n    de_batch,en_batch,de_pad_mask,en_pad_mask = [],[],[],[]\n    \n    for de_tensor,en_tensor in batch:\n        \n        de_tensor,de_mask = pad_or_truncate(de_tensor,pad_value=de_vocab[\"<pad>\"])\n        en_tensor,en_mask = pad_or_truncate(en_tensor,pad_value=en_vocab[\"<pad>\"])\n        \n        de_batch.append(de_tensor)\n        en_batch.append(en_tensor)\n        de_pad_mask.append(de_mask)\n        en_pad_mask.append(en_mask)\n        \n    de_batch = torch.stack(de_batch)\n    en_batch = torch.stack(en_batch)\n    en_pad_mask = torch.stack(en_pad_mask)\n    de_pad_mask = torch.stack(de_pad_mask)      \n    \n    return de_batch,en_batch , en_pad_mask , de_pad_mask\n\ntrain_dataloader = DataLoader(dataset=train_dataset,\n                              batch_size=ModelArgs.batch_size,\n                              collate_fn=collate_fn,\n                              drop_last=True,\n                              shuffle=True)\n\nval_dataloader = DataLoader(dataset=val_dataset,\n                            batch_size=ModelArgs.batch_size,\n                            collate_fn=collate_fn,\n                            drop_last=True,\n                            shuffle=True)\n\ntest_dataloader = DataLoader(dataset=test_dataset,\n                             batch_size=ModelArgs.batch_size,\n                             collate_fn=collate_fn,\n                             drop_last=True,\n                             shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2025-06-24T03:30:15.887060Z","iopub.execute_input":"2025-06-24T03:30:15.887268Z","iopub.status.idle":"2025-06-24T03:30:15.925056Z","shell.execute_reply.started":"2025-06-24T03:30:15.887253Z","shell.execute_reply":"2025-06-24T03:30:15.924425Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"sample_de,sample_en,sample_de_mask,sample_en_mask = next(iter(train_dataloader))\n\nsample_de.shape,sample_en.shape,sample_de_mask.shape,sample_en_mask.shape","metadata":{"execution":{"iopub.status.busy":"2025-06-24T03:30:16.096048Z","iopub.execute_input":"2025-06-24T03:30:16.096341Z","iopub.status.idle":"2025-06-24T03:30:16.135141Z","shell.execute_reply.started":"2025-06-24T03:30:16.096320Z","shell.execute_reply":"2025-06-24T03:30:16.134601Z"},"trusted":true},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(torch.Size([32, 50]),\n torch.Size([32, 50]),\n torch.Size([32, 50]),\n torch.Size([32, 50]))"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# s = torch.randn(size=[100,100])\n\n# s[:,sample_en_mask[0]==0] = float('-inf')\n\n# s","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T03:30:16.340224Z","iopub.execute_input":"2025-06-24T03:30:16.340481Z","iopub.status.idle":"2025-06-24T03:30:16.343796Z","shell.execute_reply.started":"2025-06-24T03:30:16.340460Z","shell.execute_reply":"2025-06-24T03:30:16.343238Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"\nclass Embeddings(nn.Module):\n    def __init__(self,vocab_size,embedding_dim):\n        super().__init__()\n        self.embedding_layer = nn.Embedding(num_embeddings=vocab_size,embedding_dim=embedding_dim)\n        \n    def forward(self,X):\n        return self.embedding_layer(X)","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:04:54.817072Z","iopub.execute_input":"2025-06-24T04:04:54.817608Z","iopub.status.idle":"2025-06-24T04:04:54.821698Z","shell.execute_reply.started":"2025-06-24T04:04:54.817584Z","shell.execute_reply":"2025-06-24T04:04:54.821033Z"},"trusted":true},"outputs":[],"execution_count":62},{"cell_type":"code","source":"class PositionEmbedding(nn.Module):\n    def __init__(self,d_model):\n        super().__init__()\n        # d_model : embedding_dim \n        self.d_model = d_model\n    def forward(self):\n        def sin_fun(pos,i):\n            return math.sin(pos / 10000 ** (2 * i / self.d_model) )\n        def cos_fun(pos,i):\n            return math.cos(pos / 10000 ** (2 * i / self.d_model) )\n        funs = [sin_fun,cos_fun]\n        pos_tensor = torch.stack( [torch.tensor([fun(pos,i) for fun in funs for i in range(0,self.d_model//2 - 1 + 1)],device=ModelArgs.device) for pos in range(ModelArgs.seq_len)] ) \n        # -1 + 1 becuase : by default the loop excludes the last step\n        pos_tensor_for_batch = pos_tensor.unsqueeze(0).repeat(ModelArgs.batch_size,1,1)\n        \n        # embeddings = embeddings + pos_tensor_for_batch\n        \n        return pos_tensor_for_batch","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:04:55.370196Z","iopub.execute_input":"2025-06-24T04:04:55.370857Z","iopub.status.idle":"2025-06-24T04:04:55.376412Z","shell.execute_reply.started":"2025-06-24T04:04:55.370837Z","shell.execute_reply":"2025-06-24T04:04:55.375733Z"},"trusted":true},"outputs":[],"execution_count":63},{"cell_type":"code","source":"class SelfAttention(nn.Module):\n    def __init__(self,embedding_dim,q_dim,k_dim,v_dim,attn_dropout,mask=False,):\n        super().__init__()\n        self.mask = mask\n        self.embedding_dim = embedding_dim\n        self.w_q = nn.Linear(in_features=embedding_dim,out_features=q_dim)\n        self.w_k = nn.Linear(in_features=embedding_dim,out_features=k_dim)\n        self.w_v = nn.Linear(in_features=embedding_dim,out_features=v_dim)\n        self.dropout = nn.Dropout(p=attn_dropout)\n        \n    def forward(self,embeddings,pad_mask):\n        # embeddings : [batch_size , seq_len , embedding_dim]\n        # print(f\"embedding : {embeddings.device}\")\n        # print(f\"w_q : {self.w_q.weight.device}\")\n        # print(f\"{self.w_q.dtype}\")\n        # if torch.isnan(embeddings).any():\n        #     print(\"input embeddings to self attention is nan\")\n        query = self.w_q(embeddings) # [batch_size , seq_len , q_dim]\n        key = self.w_k(embeddings) # [batch_size , seq_len , k_dim]\n        value = self.w_v(embeddings) # [batch_size , seq_len , v_dm]\n        \n        similarity_scores = torch.bmm(query , key.transpose(-2,-1)) # [batch_size , seq_len ,seq_len]\n        \n        # if torch.isnan(similarity_scores).any():\n        #     print(\"scores in sa after q@k is nan\")\n        \n        scaled_similarity_score = similarity_scores * (1 / math.sqrt(self.embedding_dim)) # [batch_size , seq_len ,seq_len]\n        \n        # if torch.isnan(scaled_similarity_score).any():\n        #     print(\"score in sa after scaling is nan\")\n        \n        if self.mask :\n            mask = torch.ones_like(scaled_similarity_score)\n            mask = torch.tril(mask)\n            scaled_similarity_score = scaled_similarity_score.masked_fill(mask==0,float('-inf'))\n            \n        # if torch.isnan(scaled_similarity_score).any():\n        #     print(\"scores in sa after masking is nan\")\n            \n        if pad_mask != None:\n            q_mask = pad_mask.unsqueeze(2) # [batch_size,seq_len] -> [batch_size,seq_len,1]\n            k_mask = pad_mask.unsqueeze(1) # [batch_size,seq_len] -> [batch_size,1,seq_len]\n            full_mask = q_mask & k_mask # [batch_size , seq_len , seq_len]\n            identity = torch.eye(n=ModelArgs.seq_len,device=ModelArgs.device).unsqueeze(0).expand(ModelArgs.batch_size,-1,-1)\n            full_mask = full_mask + identity # if all values in row becomes -inf the max = -inf then at stabilizing we got (-inf)-(-inf) = NaN so we prevent all values becoming -inf , we make the diagonal 1 by identity matrix\n            scaled_similarity_score = scaled_similarity_score.masked_fill(full_mask==0,float('-inf'))\n        \n        # if torch.isnan(scaled_similarity_score).any():\n        #     print(\"scores in sa after pad mask is nan\")\n            \n        # Stabilize Attention Scores Before Softmax -> since the values becomming nan after softmax\n        # if X = [x1,x2.....xn] if xi is very large or very small the exp(xi) will overflow and leads to nan values so we stabilize them\n        scaled_similarity_score = scaled_similarity_score - scaled_similarity_score.max(dim=-1,keepdim=True).values # .values -> the max returns both indicies and values we access values by .values\n        \n        # if torch.isnan(scaled_similarity_score).any():\n        #     print(\"scores in sa after stabilize is nan\")\n\n        weights = torch.softmax(scaled_similarity_score , dim = -1) # # [batch_size , seq_len ,seq_len]\n        # if torch.isnan(weights).any():\n        #     print(\"scores in sa after softmax is nan\")\n        \n        weights = self.dropout(weights)\n        # if torch.isnan(weights).any():\n        #     print(\"scores in sa after dropout is nana\")\n        \n        contextual_embedding = torch.matmul(weights,value) # [batch_size , seq_len ,seq_len] @ [batch_size , seq_len , v_dim]\n        \n        # if torch.isnan(contextual_embedding).any():\n        #     print(\"embeddings in sa after weight@v is nan\")\n        \n        return contextual_embedding # [batch_size , seq_len , v_dim]","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:04:55.423905Z","iopub.execute_input":"2025-06-24T04:04:55.424080Z","iopub.status.idle":"2025-06-24T04:04:55.433221Z","shell.execute_reply.started":"2025-06-24T04:04:55.424066Z","shell.execute_reply":"2025-06-24T04:04:55.432469Z"},"trusted":true},"outputs":[],"execution_count":64},{"cell_type":"code","source":"s = torch.ones(size=[4,4])\ntorch.tril(s)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T04:04:55.582006Z","iopub.execute_input":"2025-06-24T04:04:55.582393Z","iopub.status.idle":"2025-06-24T04:04:55.588209Z","shell.execute_reply.started":"2025-06-24T04:04:55.582375Z","shell.execute_reply":"2025-06-24T04:04:55.587659Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"tensor([[1., 0., 0., 0.],\n        [1., 1., 0., 0.],\n        [1., 1., 1., 0.],\n        [1., 1., 1., 1.]])"},"metadata":{}}],"execution_count":65},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self,embedding_dim,num_heads,attn_dropout):\n        super().__init__()\n        # self.embedding_layer = Embeddings(vocab_size=vocab_size,embedding_dim=embedding_dim)\n        # self.position_encoding = PositionEmbedding(d_model=embedding_dim)\n        self.multi_head_attention = nn.ModuleList([SelfAttention(embedding_dim=embedding_dim,q_dim=embedding_dim,k_dim=embedding_dim,v_dim=embedding_dim,attn_dropout=attn_dropout) for i in range(num_heads)])\n        self.dropout = nn.Dropout(p=attn_dropout)\n        self.ce_proj = nn.Linear(in_features=num_heads * embedding_dim , out_features=embedding_dim)\n        \n    def forward(self,embeddings,pad_mask):\n        # # print(f\"input shape : {embeddings.shape}\")\n        # embeddings = self.embedding_layer(embeddings)\n        # # print(f\"embedding : {embeddings.shape}\")\n        # embeddings = self.position_encoding(embeddings)\n        # # print(f\"pe + embedding : {embeddings.shape}\")\n        embeddings = torch.stack([self_attention(embeddings,pad_mask) for self_attention in self.multi_head_attention]) # [num_heads , batch_size , seq_len , embedding_dim] # embedding_dim = head_dim\n        # if torch.isnan(embeddings).any():\n        #     print(\"embeddings in mha after self attention is nan\")\n        # # print(f\"multi head embeddings : {embeddings.shape}\")\n        embeddings = embeddings.permute(1,2,0,3) # [batch_size , seq_len , num_heads , head_dim]\n        # if torch.isnan(embeddings).any():\n        #     print(\"embeddings in mha after permute is nan\")\n        embeddings = embeddings.reshape(ModelArgs.batch_size ,ModelArgs.seq_len , -1 )\n        # if torch.isnan(embeddings).any():\n        #     print(\"embeddings in mha after reshape is nan\")\n        multi_head_embeddings = self.ce_proj(embeddings) # linear does not work with 4D tensors\n        # if torch.isnan(multi_head_embeddings).any():\n        #     print(\"embeddeings in mha after ce proj is nan\")\n        multi_head_embeddings = self.dropout(multi_head_embeddings)\n        # if torch.isnan(multi_head_embeddings).any():\n        #     print(\"embeddings in mha after dropout is nan\")\n        return multi_head_embeddings","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:04:55.756425Z","iopub.execute_input":"2025-06-24T04:04:55.756619Z","iopub.status.idle":"2025-06-24T04:04:55.762372Z","shell.execute_reply.started":"2025-06-24T04:04:55.756604Z","shell.execute_reply":"2025-06-24T04:04:55.761818Z"},"trusted":true},"outputs":[],"execution_count":66},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# eb.shape","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:05:00.781053Z","iopub.execute_input":"2025-06-24T04:05:00.781950Z","iopub.status.idle":"2025-06-24T04:05:00.785142Z","shell.execute_reply.started":"2025-06-24T04:05:00.781922Z","shell.execute_reply":"2025-06-24T04:05:00.784484Z"},"trusted":true},"outputs":[],"execution_count":67},{"cell_type":"code","source":"class LayerNorm(nn.Module):\n    def __init__(self,embedding_dim):\n        super().__init__()\n        self.layer_norm = nn.LayerNorm(normalized_shape=embedding_dim)\n        \n    def forward(self,input_for_norm ):\n        return self.layer_norm(input_for_norm)","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:05:00.786306Z","iopub.execute_input":"2025-06-24T04:05:00.786559Z","iopub.status.idle":"2025-06-24T04:05:00.800766Z","shell.execute_reply.started":"2025-06-24T04:05:00.786543Z","shell.execute_reply":"2025-06-24T04:05:00.800150Z"},"trusted":true},"outputs":[],"execution_count":68},{"cell_type":"code","source":"class AddResidual(nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,X1,X2):\n        return X1+X2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T04:05:00.958112Z","iopub.execute_input":"2025-06-24T04:05:00.958285Z","iopub.status.idle":"2025-06-24T04:05:00.961954Z","shell.execute_reply.started":"2025-06-24T04:05:00.958272Z","shell.execute_reply":"2025-06-24T04:05:00.961338Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"class FeedForwardNeuralNetwork(nn.Module):\n    def __init__(self,embedding_dim,no_of_neurons,dropout):\n        super().__init__()\n        self.feed_nn = nn.Sequential(\n            nn.Linear(in_features=embedding_dim,out_features=no_of_neurons),\n            # nn.ReLU(),\n            nn.GELU(),\n            nn.Linear(in_features=no_of_neurons,out_features=embedding_dim),\n            nn.Dropout(p=dropout)\n        )\n        \n    def forward(self,X):\n        return self.feed_nn(X)","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:05:01.153949Z","iopub.execute_input":"2025-06-24T04:05:01.154147Z","iopub.status.idle":"2025-06-24T04:05:01.158545Z","shell.execute_reply.started":"2025-06-24T04:05:01.154132Z","shell.execute_reply":"2025-06-24T04:05:01.157830Z"},"trusted":true},"outputs":[],"execution_count":70},{"cell_type":"code","source":"t = torch.full(size=[4,4],fill_value=float('-inf'))\nt = torch.triu(t,diagonal=1)\nprint(t)","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:05:01.414643Z","iopub.execute_input":"2025-06-24T04:05:01.414873Z","iopub.status.idle":"2025-06-24T04:05:01.421031Z","shell.execute_reply.started":"2025-06-24T04:05:01.414856Z","shell.execute_reply":"2025-06-24T04:05:01.420477Z"},"trusted":true},"outputs":[{"name":"stdout","text":"tensor([[0., -inf, -inf, -inf],\n        [0., 0., -inf, -inf],\n        [0., 0., 0., -inf],\n        [0., 0., 0., 0.]])\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"class MaskedMultiHeadAttention(nn.Module):\n    def __init__(self,embedding_dim,num_heads,attn_dropout):\n        super().__init__()\n        self.masked_multi_head_attention = nn.ModuleList([SelfAttention(embedding_dim=embedding_dim,\n                                                                        q_dim=embedding_dim,\n                                                                        k_dim=embedding_dim,\n                                                                        v_dim=embedding_dim,\n                                                                        attn_dropout=attn_dropout,\n                                                                        mask=True) for i in range(num_heads)])\n\n        self.ce_proj = nn.Linear(in_features=num_heads*embedding_dim , out_features=embedding_dim)\n        self.dropout = nn.Dropout(p=attn_dropout)\n    def forward(self,embeddings,pad_mask):\n        # print(\"masked attention\")\n        embeddings = torch.stack([self_attention(embeddings,pad_mask) for self_attention in self.masked_multi_head_attention])\n        # if torch.isnan(embeddings).any():\n        #     print(\"self attention\")\n        embeddings = embeddings.permute(1,2,0,3) # [batch_size , seq_len , num_heads , head_dim]\n        embeddings = embeddings.reshape(ModelArgs.batch_size ,ModelArgs.seq_len , -1 )\n        multi_head_embeddings = self.ce_proj(embeddings)\n        multi_head_embeddings = self.dropout(multi_head_embeddings)\n        return multi_head_embeddings\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:05:04.459381Z","iopub.execute_input":"2025-06-24T04:05:04.459647Z","iopub.status.idle":"2025-06-24T04:05:04.465563Z","shell.execute_reply.started":"2025-06-24T04:05:04.459627Z","shell.execute_reply":"2025-06-24T04:05:04.464937Z"},"trusted":true},"outputs":[],"execution_count":72},{"cell_type":"code","source":"class CrossAttention(nn.Module):\n    def __init__(self,embedding_dim,q_dim,k_dim,v_dim,attn_dropout):\n        super().__init__()\n        self.embedding_dim = embedding_dim\n        self.w_q = nn.Linear(in_features=embedding_dim,out_features=q_dim)\n        self.w_k = nn.Linear(in_features=embedding_dim,out_features=k_dim)\n        self.w_v = nn.Linear(in_features=embedding_dim,out_features=v_dim)\n        self.dropout = nn.Dropout(p=attn_dropout)\n        \n    def forward(self,encoder_embeddings,decoder_embeddings,encoder_pad_mask,decoder_pad_mask):\n        query = self.w_q(decoder_embeddings) # [batch_size , out_seq_len , embedding_dim]\n        key = self.w_k(encoder_embeddings) # [batch_size , in_seq_len , embedding_dim]\n        value = self.w_v(encoder_embeddings) # [batch_size , in_seq_len , embedding_dim]\n        \n        similarity_scores = torch.bmm(query,key.transpose(-2,-1)) # [batch_size , out_seq_len, in_seq_len]\n        \n        scaled_similarity_scores = similarity_scores * (1 / math.sqrt(self.embedding_dim)) # [batch_size , out_seq_len , in_seq_len]\n        \n        if encoder_pad_mask != None and decoder_pad_mask != None:\n            encoder_pad_mask = encoder_pad_mask.unsqueeze(1) # [batch_size , in_seq_len] -> [batch_size ,1 , in_seq_len]\n            decoder_pad_mask = decoder_pad_mask.unsqueeze(2) # [batch_size , out_seq_len] -> [batch_size , out_seq_len, 1]\n            full_mask = encoder_pad_mask & decoder_pad_mask\n            eye = torch.eye(n=ModelArgs.seq_len,device=ModelArgs.device).unsqueeze(0).expand(ModelArgs.batch_size,-1,-1)\n            full_mask = full_mask + eye\n            \n            scaled_similarity_scores = scaled_similarity_scores.masked_fill(full_mask==0,float('-inf'))\n            \n        weights = torch.softmax(scaled_similarity_scores , dim = -1) # [batch_size , out_seq_len , in_seq_len]    \n        \n        # print(f\"weight : {weights.shape}\")\n        # print(f\"value : {value.shape}\")\n        weights = self.dropout(weights)\n        contextual_embedding = torch.matmul(weights , value)\n        \n        return contextual_embedding\n        ","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:05:04.571588Z","iopub.execute_input":"2025-06-24T04:05:04.571823Z","iopub.status.idle":"2025-06-24T04:05:04.578492Z","shell.execute_reply.started":"2025-06-24T04:05:04.571800Z","shell.execute_reply":"2025-06-24T04:05:04.577939Z"},"trusted":true},"outputs":[],"execution_count":73},{"cell_type":"code","source":"class MultiHeadCrossAttention(nn.Module):\n    def __init__(self,num_heads,embedding_dim,attn_dropout):\n        super().__init__()\n        self.multi_head_cross_attention = nn.ModuleList([CrossAttention(embedding_dim=embedding_dim,q_dim=embedding_dim,k_dim=embedding_dim,v_dim=embedding_dim,attn_dropout=attn_dropout) for i in range(num_heads)])\n        self.ce_proj = nn.Linear(in_features=num_heads*embedding_dim,out_features=embedding_dim)\n        self.dropout = nn.Dropout(p=attn_dropout)\n        \n    def forward(self,encoder_embeddings,decoder_embeddings,encoder_pad_mask,decoder_pad_mask):\n        embeddings = torch.stack([cross_attention(encoder_embeddings=encoder_embeddings,decoder_embeddings=decoder_embeddings,encoder_pad_mask=encoder_pad_mask,decoder_pad_mask=decoder_pad_mask) for cross_attention in self.multi_head_cross_attention]) # each output of size -> [batch_size,seq_len,embedding_dim]\n        embeddings = embeddings.permute(1,2,0,3) # [batch_size , seq_len , num_heads , head_dim]\n        embeddings = embeddings.reshape(ModelArgs.batch_size ,ModelArgs.seq_len , -1 )\n        multi_head_cross_attention = self.ce_proj(embeddings)\n        multi_head_cross_attention = self.dropout(multi_head_cross_attention)\n        return multi_head_cross_attention","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:05:04.772120Z","iopub.execute_input":"2025-06-24T04:05:04.772296Z","iopub.status.idle":"2025-06-24T04:05:04.777931Z","shell.execute_reply.started":"2025-06-24T04:05:04.772282Z","shell.execute_reply":"2025-06-24T04:05:04.777152Z"},"trusted":true},"outputs":[],"execution_count":74},{"cell_type":"code","source":"class EncoderBlock(nn.Module):\n    def __init__(self,num_heads,embedding_dim,ff_units,attn_dropout,dropout):\n        super().__init__()\n        # self.embedding_layer = Embeddings(vocab_size=vocab_size,embedding_dim=embedding_dim)\n        # self.position_encoding = PositionEmbedding(d_model=embedding_dim)\n        self.multi_head_attention = MultiHeadAttention(embedding_dim=embedding_dim,num_heads=num_heads,attn_dropout=attn_dropout)\n        self.norm1 = LayerNorm(embedding_dim=embedding_dim)\n        self.feed_nn = FeedForwardNeuralNetwork(embedding_dim=embedding_dim,no_of_neurons=ff_units,dropout=dropout)\n        self.norm2 = LayerNorm(embedding_dim=embedding_dim)\n        self.add = AddResidual()\n        \n    def forward(self,embeddings,pad_mask):\n        # print(\"encoder\")\n        # embeddings = self.embedding_layer(input) # [batch_size , seq_len , embedding_dim]\n        # positional_encoding = self.position_encoding() # [batch_size,seq_len , embedding_dim]\n        # embeddings = embeddings + positional_encoding # [batch_size , seq_len , embedding_dim]\n\n        # contextual_embeddings = self.multi_head_attention(embeddings,pad_mask) # [batch_size , seq_len , embedding_dim]\n\n        # contextual_embeddings_norm = self.norm1(input_for_norm=contextual_embeddings ) # [batch_size , seq_len , embedding_dim]\n\n        # contextual_embeddings_norm_fn = self.feed_nn(X=contextual_embeddings_norm) # [batch_size,seq_len,embedding_dim]\n\n        # contextual_embeddings_norm_fn_norm = self.norm2(input_for_norm=contextual_embeddings_norm_fn) # [batch_size,seq_len,embedding_dim]\n\n\n        embeddings_norm = self.norm1(input_for_norm=embeddings)\n        embeddings_norm_mha = self.multi_head_attention(embeddings_norm,pad_mask)\n        embeddings_norm_mha_add = self.add(embeddings,embeddings_norm_mha)\n\n        embeddings_norm_mha_add_norm = self.norm2(input_for_norm=embeddings_norm_mha_add)\n        embeddings_norm_mha_add_norm_fn = self.feed_nn(X=embeddings_norm_mha_add_norm)\n        embeddubgs_norm_mha_add_norm_fn_add = self.add(embeddings,embeddings_norm_mha_add_norm_fn)        \n        \n        \n        return embeddubgs_norm_mha_add_norm_fn_add # [batch_size,seq_len,embedding_dim]","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:07:10.010705Z","iopub.execute_input":"2025-06-24T04:07:10.011319Z","iopub.status.idle":"2025-06-24T04:07:10.017287Z","shell.execute_reply.started":"2025-06-24T04:07:10.011297Z","shell.execute_reply":"2025-06-24T04:07:10.016558Z"},"trusted":true},"outputs":[],"execution_count":89},{"cell_type":"code","source":"class DecoderBlock(nn.Module):\n    def __init__(self,embedding_dim,num_heads,ff_units,attn_dropout,dropout):\n        super().__init__()\n        # self.embedding_layer = Embeddings(vocab_size=vocab_size,embedding_dim=embedding_dim)\n        # self.positional_encoding = PositionEmbedding(d_model=embedding_dim)\n        self.masked_multi_head_attention = MaskedMultiHeadAttention(embedding_dim=embedding_dim,num_heads=num_heads,attn_dropout=attn_dropout)\n        self.norm1 = LayerNorm(embedding_dim=embedding_dim)\n        self.multi_head_cross_attention = MultiHeadCrossAttention(num_heads=num_heads,embedding_dim=embedding_dim,attn_dropout=attn_dropout)\n        self.norm2 = LayerNorm(embedding_dim=embedding_dim)\n        self.feed_nn = FeedForwardNeuralNetwork(embedding_dim=embedding_dim,no_of_neurons=ff_units,dropout=dropout)\n        self.norm3 = LayerNorm(embedding_dim=embedding_dim)\n        self.add = AddResidual()\n        \n    def forward(self,embeddings,encoder_embeddings,encoder_pad_mask,decoder_pad_mask):\n        # embeddings = self.embedding_layer(input) # [batch_size,seq_len,embedding_dim]\n        # positional_encoding = self.positional_encoding()\n        # embeddings = embeddings+positional_encoding\n        \n        # embeddings_mmha = self.masked_multi_head_attention(embeddings=embeddings,pad_mask=decoder_pad_mask)\n\n        # embeddings_mmha_norm = self.add_norm1(input_for_norm=embeddings_mmha,residual=embeddings)\n        # embeddings_mmha_norm_mhca = self.multi_head_cross_attention(encoder_embeddings=encoder_embeddings,decoder_embeddings=embeddings_mmha_norm,encoder_pad_mask=encoder_pad_mask,decoder_pad_mask=decoder_pad_mask)\n\n        # embeddings_mmha_norm_mhca_norm = self.add_norm2(input_for_norm=embeddings_mmha_norm_mhca,residual=embeddings_mmha_norm)\n        # embeddings_mmha_norm_mhca_norm_ffnn = self.feed_nn(X=embeddings_mmha_norm_mhca_norm)\n        # embeddings_mmha_norm_mhca_norm_ffnn_norm = self.add_norm3(input_for_norm=embeddings_mmha_norm_mhca_norm_ffnn,residual=embeddings_mmha_norm_mhca_norm)\n\n\n        embeddings_norm = self.norm1(embeddings)\n        embeddings_norm_mmha = self.masked_multi_head_attention(embeddings=embeddings,pad_mask=decoder_pad_mask)\n        embeddings_norm_mmha_add = self.add(embeddings,embeddings_norm_mmha)\n        \n        embeddings_norm_mmha_add_norm = self.norm2(embeddings_norm_mmha_add)\n        embeddings_norm_mmha_add_norm_mhca = self.multi_head_cross_attention(encoder_embeddings=encoder_embeddings,decoder_embeddings=embeddings,encoder_pad_mask=encoder_pad_mask,decoder_pad_mask=decoder_pad_mask)\n        embeddings_norm_mmha_add_norm_mhca_add = self.add(embeddings_norm_mmha_add ,embeddings_norm_mmha_add_norm_mhca )\n\n        embeddings_norm_mmha_add_norm_mhca_add_norm = self.norm3(embeddings_norm_mmha_add_norm_mhca_add)\n        embeddings_norm_mmha_add_norm_mhca_add_norm_fn = self.feed_nn(X=embeddings_norm_mmha_add_norm_mhca_add_norm)\n        embeddings_norm_mmha_add_norm_mhca_add_norm_fn_add = self.add(embeddings_norm_mmha_add_norm_mhca_add ,embeddings_norm_mmha_add_norm_mhca_add_norm_fn )\n        return embeddings_norm_mmha_add_norm_mhca_add_norm_fn_add\n","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:05:26.928124Z","iopub.execute_input":"2025-06-24T04:05:26.928387Z","iopub.status.idle":"2025-06-24T04:05:26.935814Z","shell.execute_reply.started":"2025-06-24T04:05:26.928367Z","shell.execute_reply":"2025-06-24T04:05:26.935055Z"},"trusted":true},"outputs":[],"execution_count":81},{"cell_type":"code","source":"class TransformerBlock(nn.Module):\n    def __init__(self,nx,num_heads,src_vocab_size,dest_vocab_size,embedding_dim,ff_units,attn_dropout,dropout):\n        super().__init__()\n        self.src_embedding_layer = Embeddings(vocab_size=src_vocab_size,embedding_dim=embedding_dim)\n        self.dest_embedding_layer = Embeddings(vocab_size=dest_vocab_size,embedding_dim=embedding_dim)\n        self.positional_encoding = PositionEmbedding(d_model=embedding_dim)\n        self.encoders = nn.ModuleList([EncoderBlock(num_heads=num_heads,\n                                      embedding_dim=embedding_dim,\n                                      ff_units=ff_units,\n                                      attn_dropout=attn_dropout,\n                                      dropout=dropout) for i in range(nx)])\n        self.decoders = nn.ModuleList([DecoderBlock(embedding_dim=embedding_dim,\n                                      num_heads=num_heads,\n                                      ff_units=ff_units,\n                                      attn_dropout=attn_dropout,\n                                      dropout=dropout) for i in range(nx)])\n        \n    def forward(self,X,y,X_pad_mask,y_pad_mask):\n        X_embedded = self.src_embedding_layer(X)\n        y_embedded = self.dest_embedding_layer(y)\n        \n        # if torch.isnan(X_embedded).any():\n        #     print(\"X_embd is nan before pe\")\n        # if torch.isnan(y_embedded).any():\n        #     print(\"y embd is nan before pe\")\n        \n        positional_encoding = self.positional_encoding()\n        X_embedded = X_embedded + positional_encoding\n        y_embedded = y_embedded + positional_encoding\n        \n        # if torch.isnan(X_embedded).any():\n        #     print(\"X_embd is nan after pe\")\n        # if torch.isnan(y_embedded).any():\n        #     print(\"y embd is nan after pe\")\n\n        \n        \n        for encoder in self.encoders:\n            X_embedded = encoder(embeddings=X_embedded,pad_mask=X_pad_mask)\n            \n        for decoder in self.decoders:\n            y_embedded = decoder(embeddings=y_embedded,encoder_embeddings=X_embedded,encoder_pad_mask=X_pad_mask,decoder_pad_mask=y_pad_mask)\n        \n        return X_embedded,y_embedded\n        \n        \n        ","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:05:27.251583Z","iopub.execute_input":"2025-06-24T04:05:27.251848Z","iopub.status.idle":"2025-06-24T04:05:27.258599Z","shell.execute_reply.started":"2025-06-24T04:05:27.251830Z","shell.execute_reply":"2025-06-24T04:05:27.257930Z"},"trusted":true},"outputs":[],"execution_count":82},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self,nx,num_heads,src_vocab_size,dest_vocab_size,embedding_dim,ff_units,attn_dropout,dropout):\n        super().__init__()\n        self.transformer = TransformerBlock(nx,num_heads,src_vocab_size,dest_vocab_size,embedding_dim,ff_units,attn_dropout=attn_dropout,dropout=dropout)\n        self.classification_head = nn.Sequential(\n            nn.Linear(in_features=embedding_dim,out_features=dest_vocab_size),\n            nn.Softmax(dim=-1)\n        )\n\n        self.apply(self._init_weights)\n\n    def _init_weights(self,module):\n        if isinstance(module,nn.Linear):\n            nn.init.xavier_uniform_(module.weight)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n        elif isinstance(module,nn.Embedding):\n            nn.init.xavier_uniform_(module.weight)\n        elif isinstance(module,nn.LayerNorm):\n            nn.init.ones_(module.weight)\n            nn.init.zeros_(module.bias)\n\n    def forward(self,X,y,X_pad_mask,y_pad_mask):\n        encoder_outputs,decoder_outputs = self.transformer(X=X,y=y,X_pad_mask=X_pad_mask,y_pad_mask=y_pad_mask)\n        logits = self.classification_head(decoder_outputs)\n        \n        return logits\n    ","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:05:27.459378Z","iopub.execute_input":"2025-06-24T04:05:27.459559Z","iopub.status.idle":"2025-06-24T04:05:27.465623Z","shell.execute_reply.started":"2025-06-24T04:05:27.459546Z","shell.execute_reply":"2025-06-24T04:05:27.464943Z"},"trusted":true},"outputs":[],"execution_count":83},{"cell_type":"code","source":"ModelArgs.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:05:31.256034Z","iopub.execute_input":"2025-06-24T04:05:31.256690Z","iopub.status.idle":"2025-06-24T04:05:31.260026Z","shell.execute_reply.started":"2025-06-24T04:05:31.256665Z","shell.execute_reply":"2025-06-24T04:05:31.259255Z"},"trusted":true},"outputs":[],"execution_count":84},{"cell_type":"code","source":"model = Transformer(nx=5,\n                    num_heads=4,\n                    src_vocab_size=ModelArgs.de_vocab_size,\n                    dest_vocab_size=ModelArgs.en_vocab_size,\n                    embedding_dim=ModelArgs.embedding_dim,\n                    ff_units=ModelArgs.no_of_neurons_ffnn,\n                    attn_dropout=ModelArgs.attn_dropout,\n                    dropout=ModelArgs.dropout)\n\n","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:07:15.420893Z","iopub.execute_input":"2025-06-24T04:07:15.421442Z","iopub.status.idle":"2025-06-24T04:07:16.288800Z","shell.execute_reply.started":"2025-06-24T04:07:15.421420Z","shell.execute_reply":"2025-06-24T04:07:16.288171Z"},"trusted":true},"outputs":[],"execution_count":90},{"cell_type":"code","source":"model = model.to(ModelArgs.device)","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:07:16.289884Z","iopub.execute_input":"2025-06-24T04:07:16.290136Z","iopub.status.idle":"2025-06-24T04:07:16.379140Z","shell.execute_reply.started":"2025-06-24T04:07:16.290110Z","shell.execute_reply":"2025-06-24T04:07:16.378443Z"},"trusted":true},"outputs":[],"execution_count":91},{"cell_type":"code","source":"from torchinfo import summary\n\nsummary(model=model,\n        input_data=(sample_de.to(ModelArgs.device),sample_en.to(ModelArgs.device),sample_en_mask.to(ModelArgs.device),sample_de_mask.to(ModelArgs.device)),\n        col_names=[\"input_size\",\"output_size\",\"num_params\",\"trainable\"],\n        col_width=20,\n        row_settings=[\"var_names\"],\n       device=ModelArgs.device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T04:07:28.687481Z","iopub.execute_input":"2025-06-24T04:07:28.687977Z","iopub.status.idle":"2025-06-24T04:07:28.817494Z","shell.execute_reply.started":"2025-06-24T04:07:28.687953Z","shell.execute_reply":"2025-06-24T04:07:28.816947Z"}},"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"===========================================================================================================================================================\nLayer (type (var_name))                                                     Input Shape          Output Shape         Param #              Trainable\n===========================================================================================================================================================\nTransformer (Transformer)                                                   [32, 50]             [32, 50, 297120]     --                   True\n├─TransformerBlock (transformer)                                            --                   [32, 50, 64]         --                   True\n│    └─Embeddings (src_embedding_layer)                                     [32, 50]             [32, 50, 64]         --                   True\n│    │    └─Embedding (embedding_layer)                                     [32, 50]             [32, 50, 64]         20,649,600           True\n│    └─Embeddings (dest_embedding_layer)                                    [32, 50]             [32, 50, 64]         --                   True\n│    │    └─Embedding (embedding_layer)                                     [32, 50]             [32, 50, 64]         19,015,680           True\n│    └─PositionEmbedding (positional_encoding)                              --                   [32, 50, 64]         --                   --\n│    └─ModuleList (encoders)                                                --                   --                   --                   True\n│    │    └─EncoderBlock (0)                                                --                   [32, 50, 64]         99,712               True\n│    │    └─EncoderBlock (1)                                                --                   [32, 50, 64]         99,712               True\n│    │    └─EncoderBlock (2)                                                --                   [32, 50, 64]         99,712               True\n│    │    └─EncoderBlock (3)                                                --                   [32, 50, 64]         99,712               True\n│    │    └─EncoderBlock (4)                                                --                   [32, 50, 64]         99,712               True\n│    └─ModuleList (decoders)                                                --                   --                   --                   True\n│    │    └─DecoderBlock (0)                                                --                   [32, 50, 64]         166,208              True\n│    │    └─DecoderBlock (1)                                                --                   [32, 50, 64]         166,208              True\n│    │    └─DecoderBlock (2)                                                --                   [32, 50, 64]         166,208              True\n│    │    └─DecoderBlock (3)                                                --                   [32, 50, 64]         166,208              True\n│    │    └─DecoderBlock (4)                                                --                   [32, 50, 64]         166,208              True\n├─Sequential (classification_head)                                          [32, 50, 64]         [32, 50, 297120]     --                   True\n│    └─Linear (0)                                                           [32, 50, 64]         [32, 50, 297120]     19,312,800           True\n│    └─Softmax (1)                                                          [32, 50, 297120]     [32, 50, 297120]     --                   --\n===========================================================================================================================================================\nTotal params: 60,307,680\nTrainable params: 60,307,680\nNon-trainable params: 0\nTotal mult-adds (Units.GIGABYTES): 1.93\n===========================================================================================================================================================\nInput size (MB): 0.05\nForward/backward pass size (MB): 4025.96\nParams size (MB): 241.23\nEstimated Total Size (MB): 4267.24\n==========================================================================================================================================================="},"metadata":{}}],"execution_count":94},{"cell_type":"code","source":"sample_out = model(sample_de.to(ModelArgs.device),sample_en.to(ModelArgs.device),sample_en_mask.to(ModelArgs.device),sample_de_mask.to(ModelArgs.device))","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:07:20.241254Z","iopub.execute_input":"2025-06-24T04:07:20.241513Z","iopub.status.idle":"2025-06-24T04:07:20.297920Z","shell.execute_reply.started":"2025-06-24T04:07:20.241494Z","shell.execute_reply":"2025-06-24T04:07:20.297379Z"},"trusted":true},"outputs":[],"execution_count":92},{"cell_type":"code","source":"sample_out.shape","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:07:22.270258Z","iopub.execute_input":"2025-06-24T04:07:22.270527Z","iopub.status.idle":"2025-06-24T04:07:22.275706Z","shell.execute_reply.started":"2025-06-24T04:07:22.270508Z","shell.execute_reply":"2025-06-24T04:07:22.274962Z"},"trusted":true},"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"torch.Size([32, 50, 297120])"},"metadata":{}}],"execution_count":93},{"cell_type":"code","source":"# for","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T03:31:40.821619Z","iopub.execute_input":"2025-06-24T03:31:40.822277Z","iopub.status.idle":"2025-06-24T03:31:40.825278Z","shell.execute_reply.started":"2025-06-24T03:31:40.822259Z","shell.execute_reply":"2025-06-24T03:31:40.824703Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"def train(model,model_name,train_dataloader,val_dataloader,criterion,optimizer,epochs,min_val_loss,device,wandb=None,scheduler=None,clip_grad=False):\n    from tqdm import tqdm\n    model = model.to(device)\n    train_losses,val_losses = [],[]\n    \n    best_val_loss = float('inf')\n    all_counters = []\n    \n    try:\n        for epoch in range(epochs):\n            counter = Counter()\n            train_loss,correct,total = 0.0,0,0\n            train_progress = tqdm(train_dataloader)\n            for idx,(de_batch,en_batch,de_pad_mask,en_pad_mask) in enumerate(train_progress):\n                de_batch = de_batch.to(device)\n                en_batch = en_batch.to(device)\n                de_pad_mask = de_pad_mask.to(device)\n                en_pad_mask = en_pad_mask.to(device)\n                optimizer.zero_grad()\n                all_logits = model(de_batch,en_batch,de_pad_mask,en_pad_mask) # [batch_size,seq_len,vocab_size]\n                all_logits = all_logits.view(-1,ModelArgs.en_vocab_size) # [batch_size , seq_len * vocab_size]\n                en_batch = en_batch.view(-1) # [batch_size * seq_len]\n                loss = criterion(all_logits,en_batch) \n                \n                loss.backward()\n\n                #######################################################################################################\n                if clip_grad:\n                    torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm=1.0)\n                    \n                total_norm = 0\n                for p in model.parameters():\n                    if p.grad is not None:\n                        param_norm = p.grad.data.norm(2) # L2 norm\n                        total_norm = param_norm.item()**2\n\n                total_norm = total_norm**0.5\n\n                    \n\n                # print(total_norm)\n\n                # for name,param in model.named_parameters():\n                #     if param.grad is not None:\n                #         print(f\"{name} : {param.grad.norm().item():.6f}\")\n\n                if wandb is not None:\n                    wandb.log({\"norm\":total_norm})\n\n                    grad_groups = defaultdict(list)\n\n                    for name, param in model.named_parameters():\n                        if param.grad is None:\n                            continue\n                        # Get group name: e.g., \"encoder.0\", \"decoder.1\", \"embedding\", etc.\n                        tokens = name.split('.')\n                        group_name = '.'.join(tokens[:3]) if len(tokens) >= 3 else '.'.join(tokens[:2])\n                \n                        grad_norm = param.grad.norm().item()\n                        grad_groups[group_name].append(grad_norm)\n                \n                    # Average gradients per group\n                    avg_grad_per_group = {k: sum(v)/len(v) for k, v in grad_groups.items()}\n\n                    wandb.log(avg_grad_per_group)\n\n                #####################################################################################################\n                optimizer.step()\n                if scheduler is not None:\n                    scheduler.step()\n                \n                train_loss += loss.item()\n                pred_probs = torch.softmax(all_logits,dim=-1) # [batch_size , seq_len * vocab_size]\n                preds = torch.argmax(pred_probs,dim=-1)\n                correct += (preds == en_batch).sum()\n                total +=en_batch.shape[0]\n                \n                train_progress.set_postfix({\"loss\":f\"{loss.item():.4f}\"})\n\n                train_losses.append(train_loss)\n                counter.update(preds.tolist())\n                if wandb is not None:\n                    wandb.log({\"train_loss\":train_loss/(idx+1),\"train_acc\":correct/total})\n                \n            train_loss /= len(train_dataloader)\n            train_acc = correct/total\n                \n            with torch.inference_mode():\n                val_loss,correct,total = 0.0,0,0\n                val_progress = tqdm(val_dataloader)\n                for idx,(de_batch,en_batch,de_pad_mask,en_pad_mask) in enumerate(val_progress):\n                    de_batch = de_batch.to(device)\n                    en_batch = en_batch.to(device)\n                    de_pad_mask = de_pad_mask.to(device)\n                    en_pad_mask = en_pad_mask.to(device)\n                    \n                    all_logits = model(de_batch,en_batch,de_pad_mask,en_pad_mask)\n                    all_logits = all_logits.view(-1,ModelArgs.en_vocab_size)\n                    en_batch = en_batch.view(-1)\n                    \n                    loss = criterion(all_logits,en_batch)\n\n                    pred_probs = torch.softmax(all_logits,dim=-1)\n                    preds = torch.argmax(pred_probs,dim=-1)\n                    \n                    val_loss += loss.item()\n                    correct += (preds==en_batch).sum()\n                    total += en_batch.shape[0]\n                    \n                    val_progress.set_postfix({\"loss\":f\"{loss.item():.4f}\"})\n                    \n                    val_losses.append(val_loss)\n                    if wandb is not None:\n                        wandb.log({\"val_loss\":val_loss/(idx+1),\"val_acc\":correct/total})\n                    \n                    \n                val_loss /= len(val_dataloader)\n                val_acc = correct/total\n                \n            print(f\"Epoch : {epoch}/{epochs} \\n train loss : {train_loss:.5f} train acc : {train_acc:.5f}\\n val loss : {val_loss:.5f}  val acc : {val_acc:.5f}\")\n\n            all_counters.append(counter)\n            if best_val_loss > val_loss:\n                best_val_loss = val_loss\n                torch.save(model.state_dict(),model_name)\n            \n            if val_loss < min_val_loss:\n                print(\"model trained successully\")\n                return train_losses,val_losses , all_counters\n        return train_losses,val_losses , all_counters\n    \n\n    except KeyboardInterrupt:\n        return train_losses,val_losses , all_counters\n            \n        ","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:07:32.232518Z","iopub.execute_input":"2025-06-24T04:07:32.232810Z","iopub.status.idle":"2025-06-24T04:07:32.247803Z","shell.execute_reply.started":"2025-06-24T04:07:32.232770Z","shell.execute_reply":"2025-06-24T04:07:32.247128Z"},"trusted":true},"outputs":[],"execution_count":95},{"cell_type":"code","source":"!pip install dotenv","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:07:35.992364Z","iopub.execute_input":"2025-06-24T04:07:35.992630Z","iopub.status.idle":"2025-06-24T04:07:38.893630Z","shell.execute_reply.started":"2025-06-24T04:07:35.992610Z","shell.execute_reply":"2025-06-24T04:07:38.892925Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: dotenv in /usr/local/lib/python3.11/dist-packages (0.9.9)\nRequirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from dotenv) (1.1.0)\n","output_type":"stream"}],"execution_count":96},{"cell_type":"code","source":"import os\nfrom dotenv import load_dotenv\nload_dotenv(\"/kaggle/input/wandb-key/.env\")\nwandb_key = os.getenv(\"WANDB_API_KEY\")","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:07:38.895364Z","iopub.execute_input":"2025-06-24T04:07:38.895574Z","iopub.status.idle":"2025-06-24T04:07:38.909590Z","shell.execute_reply.started":"2025-06-24T04:07:38.895555Z","shell.execute_reply":"2025-06-24T04:07:38.908902Z"},"trusted":true},"outputs":[],"execution_count":97},{"cell_type":"code","source":"import wandb\nwandb.login(key=wandb_key)","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:07:38.910328Z","iopub.execute_input":"2025-06-24T04:07:38.910550Z","iopub.status.idle":"2025-06-24T04:07:38.916701Z","shell.execute_reply.started":"2025-06-24T04:07:38.910528Z","shell.execute_reply":"2025-06-24T04:07:38.916133Z"},"trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":98},{"cell_type":"code","source":"# criterion = nn.CrossEntropyLoss(ignore_index=en_vocab[\"<pad>\"],label_smoothing=0.1)\ncriterion = nn.CrossEntropyLoss(ignore_index=en_vocab[\"<pad>\"])\n\n# optimizer = torch.optim.Adam(model.parameters(),lr=ModelArgs.max_lr)\n\nfrom torch.optim.lr_scheduler import LambdaLR\n\ndef get_lr(step, d_model=ModelArgs.embedding_dim, warmup_steps=4500):\n    step = max(step, 1)\n    return (d_model ** -0.5) * min(step ** -0.5, step * warmup_steps ** -1.5)\n\n# optimizer = torch.optim.Adam(model.parameters(), lr=1e-8)\noptimizer = torch.optim.Adam(model.parameters(),lr=1e-5)\nscheduler = LambdaLR(optimizer, lr_lambda=lambda step: get_lr(step, d_model=ModelArgs.embedding_dim))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T04:43:49.447010Z","iopub.execute_input":"2025-06-24T04:43:49.447264Z","iopub.status.idle":"2025-06-24T04:43:49.457044Z","shell.execute_reply.started":"2025-06-24T04:43:49.447248Z","shell.execute_reply":"2025-06-24T04:43:49.456284Z"}},"outputs":[],"execution_count":112},{"cell_type":"code","source":"\nwandb.init(\n    project=\"transformer_form_scratch\",\n    name=\"logging layer wise grad + warmup 4500 + lr tuning to 1e-3 + weight intialization + optimizer Adam + nx to 5 + num_heads to 4 + tuned the embedding dim 32 -> 64 + pre normalization + scheduler + 500 epochs\",\n    config={\n        \"lr\":ModelArgs.max_lr,\n        \"batch_size\":ModelArgs.batch_size,\n        \"embedding_dim\":ModelArgs.embedding_dim,\n        \"no_of_neurons_ffnn\":ModelArgs.no_of_neurons_ffnn,\n        \"seq_len\":ModelArgs.seq_len,\n        \"num_heads\":ModelArgs.num_heads,\n        \"en_vocab_size\":ModelArgs.en_vocab_size,\n        \"de_vocab_size\":ModelArgs.de_vocab_size,\n        \n    }\n)","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:44:02.862562Z","iopub.execute_input":"2025-06-24T04:44:02.862881Z","iopub.status.idle":"2025-06-24T04:44:09.888761Z","shell.execute_reply.started":"2025-06-24T04:44:02.862858Z","shell.execute_reply":"2025-06-24T04:44:09.888240Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>classification_head.0.bias</td><td>▁▅▄▃▂▄▄▅▃▆▃▅▄▂▅▃▆▅▅▆▂▅█▆▅▂█▃▇▇█▆▆▄▅▇▂▅▄█</td></tr><tr><td>classification_head.0.weight</td><td>▆▁▅▄▆▁▂▄▃▃▃▁▃▄▅▃▅▅▅▅▄▅▆▆▂▆▃▁▄█▅▄▅▇▆▇▆▆▇▇</td></tr><tr><td>norm</td><td>▃▄▄▂▅▅▃▃▇▃▃▃▇▇▄▃▇▃▆▅▃▃▆▅▂▄▃▃▇█▂▁▂▅▄▅▂▆▇▅</td></tr><tr><td>train_acc</td><td>▆██▅▅▂▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▄▄</td></tr><tr><td>train_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>transformer.decoders.0</td><td>▃▂▄▂▂▂▅▁▃▃▆▄▂▂▂▃▃▄▃▂▃▃▆▂▄▂█▁▃▂▄▃▄▁▂▂▄▂▂▇</td></tr><tr><td>transformer.decoders.1</td><td>▂▄▃▃▅▅▂▄▄▆▆▄▃▄▆▄▁▂▃▂▃▄▆█▅▄▄▂▂▁▄▇▇▃▃▄▂▆▃▃</td></tr><tr><td>transformer.decoders.2</td><td>▃▃▄▆▄▂▅▃▂▃█▃▁▁▁▄▃▂▁▄▂▅▃▂▄▃▁▃▇▂▄▃▂▁▄▁▂▄▄█</td></tr><tr><td>transformer.decoders.3</td><td>▄▄▃▄▅▁▃▅▃▃▅▂▃▁▅▄▄▃▃▅█▄▆▂▂▅▄▅▃▂▅▄▆▂▄▃▄▆▅▄</td></tr><tr><td>transformer.decoders.4</td><td>▄█▄▃▅▂▂▄▄▂▅▅▆▅▃▄▅▃▁▄▅▅▅▆▂▄▅▄▅▂▅▃█▄▄▆▇▆▄▃</td></tr><tr><td>transformer.dest_embedding_layer.embedding_layer</td><td>▂▂▂▂▂▂▂▁▂▂▂▄▂▂▁▂▂▂▂▃▁█▄▂▁▂▂▁▂▂▃▃▃▁▂▂▃▂▂▃</td></tr><tr><td>transformer.encoders.0</td><td>▃▂▃▇▂▃▆▂▁▂▂▁█▃▄▂▄▂▃▂▃▃▂▆▂▂▂▂▃▃▃▃▃▄▄▂▃▃▃▅</td></tr><tr><td>transformer.encoders.1</td><td>▃▁▃▂▃▃▄▅▃▃▄▂▂▂▃▃▃▃▂▅▃█▂▄▆▃█▂▆▅▄▂▂▃▂▃▄▄▅▇</td></tr><tr><td>transformer.encoders.2</td><td>▂▂▂▁▃▂▅▄▂▆▃▁█▂▃▁█▁▃▃▃▂▅▄▃▃▅▂▃▂▂▃▂▃▃▇▄▄▁▅</td></tr><tr><td>transformer.encoders.3</td><td>▃▄▅▂▆▂▂▂▄▂▂▃▃▁▃▃▃▃▁▄▃▄▁▆▃▂▂▂█▂▃▂▃▄▂▂▂▃▃▂</td></tr><tr><td>transformer.encoders.4</td><td>▃▂▄▃▃▂▃▃▃▂▁▃▄▂▁▃▃▄▃▂▁▃▂▂▄▃▅▁▂▃▄▃█▂▃▃▂▂▆▄</td></tr><tr><td>transformer.src_embedding_layer.embedding_layer</td><td>▃▂▂▃▂▂█▇▃▁▇▄▁▂▂▁▁▂▂▃▂▁█▄▂▂▂▂▃▂▃▂▄▄▃▄▂▁▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>classification_head.0.bias</td><td>1e-05</td></tr><tr><td>classification_head.0.weight</td><td>0.00078</td></tr><tr><td>norm</td><td>1e-05</td></tr><tr><td>train_acc</td><td>0.00022</td></tr><tr><td>train_loss</td><td>12.60189</td></tr><tr><td>transformer.decoders.0</td><td>1e-05</td></tr><tr><td>transformer.decoders.1</td><td>1e-05</td></tr><tr><td>transformer.decoders.2</td><td>0.0</td></tr><tr><td>transformer.decoders.3</td><td>0.0</td></tr><tr><td>transformer.decoders.4</td><td>0.0</td></tr><tr><td>transformer.dest_embedding_layer.embedding_layer</td><td>1e-05</td></tr><tr><td>transformer.encoders.0</td><td>1e-05</td></tr><tr><td>transformer.encoders.1</td><td>1e-05</td></tr><tr><td>transformer.encoders.2</td><td>0.0</td></tr><tr><td>transformer.encoders.3</td><td>0.0</td></tr><tr><td>transformer.encoders.4</td><td>0.0</td></tr><tr><td>transformer.src_embedding_layer.embedding_layer</td><td>1e-05</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">logging layer wise grad + lr tuning to 1e-3 + weight intialization + optimizer Adam + nx to 5 + num_heads to 4 + tuned the embedding dim 32 -> 64 + pre normalization + scheduler + 500 epochs</strong> at: <a href='https://wandb.ai/janardhanthippabattini-rajiv-gandhi-university-of-knowle/transformer_form_scratch/runs/wg8q8vfq' target=\"_blank\">https://wandb.ai/janardhanthippabattini-rajiv-gandhi-university-of-knowle/transformer_form_scratch/runs/wg8q8vfq</a><br> View project at: <a href='https://wandb.ai/janardhanthippabattini-rajiv-gandhi-university-of-knowle/transformer_form_scratch' target=\"_blank\">https://wandb.ai/janardhanthippabattini-rajiv-gandhi-university-of-knowle/transformer_form_scratch</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250624_043912-wg8q8vfq/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250624_044402-g6ftd1k2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/janardhanthippabattini-rajiv-gandhi-university-of-knowle/transformer_form_scratch/runs/g6ftd1k2' target=\"_blank\">logging layer wise grad + warmup 4500 + lr tuning to 1e-3 + weight intialization + optimizer Adam + nx to 5 + num_heads to 4 + tuned the embedding dim 32 -> 64 + pre normalization + scheduler + 500 epochs</a></strong> to <a href='https://wandb.ai/janardhanthippabattini-rajiv-gandhi-university-of-knowle/transformer_form_scratch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/janardhanthippabattini-rajiv-gandhi-university-of-knowle/transformer_form_scratch' target=\"_blank\">https://wandb.ai/janardhanthippabattini-rajiv-gandhi-university-of-knowle/transformer_form_scratch</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/janardhanthippabattini-rajiv-gandhi-university-of-knowle/transformer_form_scratch/runs/g6ftd1k2' target=\"_blank\">https://wandb.ai/janardhanthippabattini-rajiv-gandhi-university-of-knowle/transformer_form_scratch/runs/g6ftd1k2</a>"},"metadata":{}},{"execution_count":113,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/janardhanthippabattini-rajiv-gandhi-university-of-knowle/transformer_form_scratch/runs/g6ftd1k2?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7be506eed590>"},"metadata":{}}],"execution_count":113},{"cell_type":"code","source":"train_loss,val_loss,counter = train(model=model,\n      model_name=\"transformer_form_scratch.pth\",\n      train_dataloader=train_dataloader,\n      val_dataloader=val_dataloader,\n      criterion=criterion,\n      optimizer=optimizer,\n      epochs=500,\n      min_val_loss=1e-3,\n    scheduler=scheduler,\n      device=ModelArgs.device,\n        clip_grad=True,\n        wandb=wandb)","metadata":{"execution":{"iopub.status.busy":"2025-06-24T04:44:11.586360Z","iopub.execute_input":"2025-06-24T04:44:11.586991Z","iopub.status.idle":"2025-06-24T05:58:26.563281Z","shell.execute_reply.started":"2025-06-24T04:44:11.586968Z","shell.execute_reply":"2025-06-24T05:58:26.562690Z"},"trusted":true},"outputs":[{"name":"stderr","text":"100%|██████████| 906/906 [03:46<00:00,  4.01it/s, loss=12.6019]\n100%|██████████| 31/31 [00:03<00:00,  9.82it/s, loss=12.6019]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 0/500 \n train loss : 12.60189 train acc : 0.00031\n val loss : 12.60189  val acc : 0.00030\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 906/906 [03:46<00:00,  4.00it/s, loss=12.6019]\n100%|██████████| 31/31 [00:03<00:00,  9.75it/s, loss=12.6019]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 1/500 \n train loss : 12.60189 train acc : 0.00031\n val loss : 12.60189  val acc : 0.00024\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 906/906 [03:45<00:00,  4.01it/s, loss=12.6019]\n100%|██████████| 31/31 [00:03<00:00, 10.04it/s, loss=12.6019]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 2/500 \n train loss : 12.60189 train acc : 0.00038\n val loss : 12.60189  val acc : 0.00048\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 906/906 [03:44<00:00,  4.04it/s, loss=12.6019]\n100%|██████████| 31/31 [00:03<00:00, 10.08it/s, loss=12.6019]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 4/500 \n train loss : 12.60189 train acc : 0.00090\n val loss : 12.60189  val acc : 0.00121\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 906/906 [03:43<00:00,  4.05it/s, loss=12.6019]\n100%|██████████| 31/31 [00:03<00:00, 10.05it/s, loss=12.6019]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 5/500 \n train loss : 12.60189 train acc : 0.00147\n val loss : 12.60189  val acc : 0.00240\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 906/906 [03:43<00:00,  4.05it/s, loss=12.6019]\n100%|██████████| 31/31 [00:03<00:00, 10.09it/s, loss=12.6019]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 6/500 \n train loss : 12.60189 train acc : 0.00240\n val loss : 12.60188  val acc : 0.00240\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 906/906 [03:44<00:00,  4.03it/s, loss=12.6019]\n100%|██████████| 31/31 [00:03<00:00,  9.97it/s, loss=12.6019]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 7/500 \n train loss : 12.60188 train acc : 0.00379\n val loss : 12.60188  val acc : 0.00494\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 906/906 [03:43<00:00,  4.05it/s, loss=12.6019]\n100%|██████████| 31/31 [00:03<00:00, 10.05it/s, loss=12.6019]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 8/500 \n train loss : 12.60188 train acc : 0.00530\n val loss : 12.60188  val acc : 0.00649\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 906/906 [03:43<00:00,  4.05it/s, loss=12.6019]\n100%|██████████| 31/31 [00:03<00:00, 10.04it/s, loss=12.6019]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 9/500 \n train loss : 12.60188 train acc : 0.00745\n val loss : 12.60188  val acc : 0.00883\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 906/906 [03:43<00:00,  4.06it/s, loss=12.6019]\n100%|██████████| 31/31 [00:03<00:00,  9.81it/s, loss=12.6019]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 10/500 \n train loss : 12.60188 train acc : 0.00995\n val loss : 12.60188  val acc : 0.01085\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 906/906 [03:44<00:00,  4.04it/s, loss=12.6019]\n100%|██████████| 31/31 [00:03<00:00,  9.89it/s, loss=12.6019]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 12/500 \n train loss : 12.60188 train acc : 0.01697\n val loss : 12.60188  val acc : 0.01974\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 906/906 [03:44<00:00,  4.04it/s, loss=12.6019]\n100%|██████████| 31/31 [00:03<00:00, 10.00it/s, loss=12.6019]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 14/500 \n train loss : 12.60188 train acc : 0.02551\n val loss : 12.60188  val acc : 0.02796\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 906/906 [03:45<00:00,  4.02it/s, loss=12.6019]\n100%|██████████| 31/31 [00:03<00:00,  9.98it/s, loss=12.6019]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 15/500 \n train loss : 12.60188 train acc : 0.02991\n val loss : 12.60188  val acc : 0.03593\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 906/906 [03:44<00:00,  4.03it/s, loss=12.6019]\n100%|██████████| 31/31 [00:03<00:00,  9.92it/s, loss=12.6019]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 16/500 \n train loss : 12.60188 train acc : 0.03514\n val loss : 12.60188  val acc : 0.03744\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 906/906 [03:44<00:00,  4.03it/s, loss=12.6019]\n100%|██████████| 31/31 [00:03<00:00,  9.92it/s, loss=12.6019]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 17/500 \n train loss : 12.60188 train acc : 0.04074\n val loss : 12.60187  val acc : 0.04319\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 906/906 [03:44<00:00,  4.03it/s, loss=12.6019]\n100%|██████████| 31/31 [00:03<00:00,  9.95it/s, loss=12.6019]\n","output_type":"stream"},{"name":"stdout","text":"Epoch : 18/500 \n train loss : 12.60187 train acc : 0.04675\n val loss : 12.60187  val acc : 0.05052\n","output_type":"stream"},{"name":"stderr","text":" 52%|█████▏    | 471/906 [01:57<01:48,  4.01it/s, loss=12.6019]\n","output_type":"stream"}],"execution_count":114},{"cell_type":"code","source":"torch.cuda.empty_cache()\ntorch.cuda.ipc_collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T05:58:30.674424Z","iopub.execute_input":"2025-06-24T05:58:30.675198Z","iopub.status.idle":"2025-06-24T05:58:30.746489Z","shell.execute_reply.started":"2025-06-24T05:58:30.675165Z","shell.execute_reply":"2025-06-24T05:58:30.745767Z"}},"outputs":[],"execution_count":115},{"cell_type":"code","source":"torch.save(train_data,\"train_data.pt\")\ntorch.save(val_data,\"val_data.pt\")\ntorch.save(test_data,\"test_data.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T05:09:51.522327Z","iopub.execute_input":"2025-06-23T05:09:51.522553Z","iopub.status.idle":"2025-06-23T05:09:53.632227Z","shell.execute_reply.started":"2025-06-23T05:09:51.522528Z","shell.execute_reply":"2025-06-23T05:09:53.631629Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"model.parameters().__next___().dtype","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T05:59:55.995444Z","iopub.execute_input":"2025-06-24T05:59:55.995919Z","iopub.status.idle":"2025-06-24T05:59:56.061377Z","shell.execute_reply.started":"2025-06-24T05:59:55.995892Z","shell.execute_reply":"2025-06-24T05:59:56.060675Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/2568135117.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next___\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"torch.save(args,\"model_args.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T05:09:53.638494Z","iopub.execute_input":"2025-06-23T05:09:53.638736Z","iopub.status.idle":"2025-06-23T05:09:53.655336Z","shell.execute_reply.started":"2025-06-23T05:09:53.638720Z","shell.execute_reply":"2025-06-23T05:09:53.654636Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"import pickle\nwith open(\"en_vocab.pkl\",\"wb\") as f:\n    pickle.dump(dict(en_vocab),f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T05:09:53.655981Z","iopub.execute_input":"2025-06-23T05:09:53.656207Z","iopub.status.idle":"2025-06-23T05:09:54.965875Z","shell.execute_reply.started":"2025-06-23T05:09:53.656192Z","shell.execute_reply":"2025-06-23T05:09:54.965293Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"with open(\"de_voab.pkl\",\"wb\") as f:\n    pickle.dump(dict(de_vocab),f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T05:09:54.966593Z","iopub.execute_input":"2025-06-23T05:09:54.966811Z","iopub.status.idle":"2025-06-23T05:09:56.238301Z","shell.execute_reply.started":"2025-06-23T05:09:54.966795Z","shell.execute_reply":"2025-06-23T05:09:56.237483Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"args = {\"en_vocab_size\":ModelArgs.en_vocab_size,\n       \"de_vocab_size\":ModelArgs.de_vocab_size}\n\nwith open(\"model_args.pkl\",\"wb\") as f:\n    pickle.dump(args,f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T05:10:11.677944Z","iopub.execute_input":"2025-06-23T05:10:11.678496Z","iopub.status.idle":"2025-06-23T05:10:11.683276Z","shell.execute_reply.started":"2025-06-23T05:10:11.678475Z","shell.execute_reply":"2025-06-23T05:10:11.682745Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}